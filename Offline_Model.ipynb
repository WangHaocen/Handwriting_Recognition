{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateOffLine():\n",
    "    with open(\"./data/offline/words.txt\") as f:\n",
    "        line = f.readlines()\n",
    "    \n",
    "    lines = []\n",
    "    for l in line:\n",
    "        if(l.startswith(\"#\")):\n",
    "            continue\n",
    "        else:\n",
    "            lines.append(l)\n",
    "\n",
    "    new_lines = []\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        splits = line.split(' ')\n",
    "        status = splits[1]\n",
    "\n",
    "        if status == 'ok':\n",
    "            new_lines.append(lines[i])\n",
    "                        \n",
    "        idx = int(0.9 * len(new_lines))\n",
    "        train_samples = new_lines[:idx]\n",
    "        test_samples = new_lines[idx:]\n",
    "        val_idx = int(0.5 * len(test_samples))\n",
    "        validation_samples = test_samples[:val_idx]\n",
    "        test_samples = test_samples[val_idx:]\n",
    "        \n",
    "    return train_samples,test_samples,validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples,test_samples,validation_samples = GenerateOffLine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a01-000u-00-00 ok 154 408 768 27 51 AT A\\n',\n",
       " 'a01-000u-00-01 ok 154 507 766 213 48 NN MOVE\\n',\n",
       " 'a01-000u-00-02 ok 154 796 764 70 50 TO to\\n',\n",
       " 'a01-000u-00-03 ok 154 919 757 166 78 VB stop\\n',\n",
       " 'a01-000u-00-04 ok 154 1185 754 126 61 NPT Mr.\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(samples):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    for i in range (len(samples)):\n",
    "        s = samples[i]\n",
    "        s = s.split(\" \")\n",
    "        file = s[0]\n",
    "        label = s[len(s)-1]\n",
    "        label = label.split(\"\\n\")[0]\n",
    "        file_path = file.split(\"-\")\n",
    "        img_path = \"./data/offline/iam/\" + file_path[0] + \"/\" + file_path[0] + \"-\" + file_path[1] + \"/\" + file + \".png\"\n",
    "        if os.path.getsize(img_path):\n",
    "            paths.append(img_path)\n",
    "            labels.append(label)\n",
    "            \n",
    "    return paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths, train_labels = get_samples(train_samples)\n",
    "validation_img_paths, validation_labels = get_samples(validation_samples)\n",
    "test_img_paths, test_labels = get_samples(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/offline/iam/a01/a01-000u/a01-000u-00-00.png',\n",
       " './data/offline/iam/a01/a01-000u/a01-000u-00-01.png',\n",
       " './data/offline/iam/a01/a01-000u/a01-000u-00-02.png',\n",
       " './data/offline/iam/a01/a01-000u/a01-000u-00-03.png',\n",
       " './data/offline/iam/a01/a01-000u/a01-000u-00-04.png']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'MOVE', 'to', 'stop', 'Mr.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = []\n",
    "max_len = 0\n",
    "for i in range(len(train_labels)):\n",
    "    label = train_labels[i]\n",
    "    for char in label:\n",
    "        characters.append(char)\n",
    "        \n",
    "    if(len(label)>max_len):\n",
    "        max_len = len(label)\n",
    "        \n",
    "characters = set(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "char_to_num = StringLookup(vocabulary=list(characters), mask_token=None)\n",
    "num_to_char = StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_free_resize(image, img_size):\n",
    "   \n",
    "    w, h = img_size\n",
    "    image  = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
    "\n",
    "    # Check tha amount of padding needed to be done.\n",
    "    pad_height = h - tf.shape(image)[0]\n",
    "    pad_width = w - tf.shape(image)[1]\n",
    "    \n",
    "    # Only necessary if you want to do same amount of padding on both sides.\n",
    "    if pad_height % 2 != 0:\n",
    "        height = pad_height // 2\n",
    "        pad_height_top = height + 1\n",
    "        pad_height_bottom = height\n",
    "    else:\n",
    "        pad_height_top = pad_height_bottom = pad_height // 2\n",
    "    \n",
    "    if pad_width % 2 != 0:\n",
    "        width = pad_width // 2\n",
    "        pad_width_left = width + 1\n",
    "        pad_width_right = width\n",
    "    else:\n",
    "        pad_width_left = pad_width_right = pad_width // 2\n",
    "   \n",
    "    image = tf.pad(\n",
    "        image,\n",
    "        paddings=[\n",
    "                  [pad_height_top, pad_height_bottom],\n",
    "                  [pad_width_left, pad_width_right],\n",
    "                  [0, 0]\n",
    "                ]\n",
    "        )\n",
    "\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "padding_token = 99\n",
    "image_width = 128\n",
    "image_height = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deslant_img import deslant_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n"
     ]
    }
   ],
   "source": [
    "prepro_img_train = []\n",
    "prepro_label_train = [] \n",
    "for i in range (len(train_img_paths)):\n",
    "    if(i%1000==0):\n",
    "        print(i)\n",
    "    path = train_img_paths[i]\n",
    "    label = train_labels[i]\n",
    "    \n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    res = deslant_img(img)\n",
    "    img = res.img\n",
    "    img = np.reshape(img,(img.shape[0],img.shape[1],1))\n",
    "    img = distortion_free_resize(img, img_size=(image_width, image_height))\n",
    "    img = tf.cast(img, tf.float32) / 255.\n",
    "    prepro_img_train.append(img)\n",
    "    \n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    length = tf.shape(label)[0]\n",
    "    pad_amount = max_len - length\n",
    "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
    "    prepro_label_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "prepro_img_valid = []\n",
    "prepro_label_valid = [] \n",
    "for i in range (len(validation_img_paths)):\n",
    "    if(i%1000==0):\n",
    "        print(i)\n",
    "    path = validation_img_paths[i]\n",
    "    label = validation_labels[i]\n",
    "    \n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    res = deslant_img(img)\n",
    "    img = res.img\n",
    "    img = np.reshape(img,(img.shape[0],img.shape[1],1))\n",
    "    img = distortion_free_resize(img, img_size=(image_width, image_height))\n",
    "    img = tf.cast(img, tf.float32) / 255.\n",
    "    prepro_img_valid.append(img)\n",
    "    \n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    length = tf.shape(label)[0]\n",
    "    pad_amount = max_len - length\n",
    "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
    "    prepro_label_valid.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "prepro_img_test = []\n",
    "prepro_label_test= [] \n",
    "for i in range (len(test_img_paths)):\n",
    "    if(i%1000==0):\n",
    "        print(i)\n",
    "    path = test_img_paths[i]\n",
    "    label = test_labels[i]\n",
    "    \n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    res = deslant_img(img)\n",
    "    img = res.img\n",
    "    img = np.reshape(img,(img.shape[0],img.shape[1],1))\n",
    "    img = distortion_free_resize(img, img_size=(image_width, image_height))\n",
    "    img = tf.cast(img, tf.float32) / 255.\n",
    "    prepro_img_test.append(img)\n",
    "    \n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    length = tf.shape(label)[0]\n",
    "    pad_amount = max_len - length\n",
    "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
    "    prepro_label_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 1)\n",
      "(21,)\n"
     ]
    }
   ],
   "source": [
    "print(prepro_img_test[0].shape)\n",
    "print(prepro_label_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image):\n",
    "    img = image\n",
    "    return img\n",
    "\n",
    "def get_label(label):\n",
    "    label_ = label\n",
    "    return label_\n",
    "\n",
    "\n",
    "def get_dataset(image_path, label):\n",
    "    image = get_image(image_path)\n",
    "    label = get_label(label)\n",
    "    return {\"xs\": image, \"ys\": label}\n",
    "\n",
    "\n",
    "def prepare_dataset(image_paths, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(\n",
    "        get_dataset, num_parallel_calls=AUTOTUNE\n",
    "    )\n",
    "    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = prepare_dataset(prepro_img_train, prepro_label_train)\n",
    "validation_tf = prepare_dataset(prepro_img_valid, prepro_label_valid)\n",
    "test_tf = prepare_dataset(prepro_img_test, prepro_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Reshape,BatchNormalization, Activation, Input, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Offline_Model(object):\n",
    "    def __init__(self,preload):\n",
    "        self.model = self.get_model()\n",
    "        self.pred_model = self.get_premodel(\"softmax\")\n",
    "        self.compile()\n",
    "        \n",
    "        if preload:\n",
    "            self.pretrained = \"./model/offline/offline_without_children_CNN2_batch64_blstm.h5\"\n",
    "            print(\"preloading model weights from\" + self.pretrained)\n",
    "            self.load_weights(file_name=self.pretrained)\n",
    "            \n",
    "    def get_premodel(self, layer_name):\n",
    "        pre_model = Model(inputs=self.model.get_layer(\"xs\").output,\n",
    "                         outputs=self.model.get_layer(layer_name).output)\n",
    "       \n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "        pre_model.compile(loss={layer_name: lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "        return pre_model\n",
    "    \n",
    "    def get_model(self):\n",
    "        input_shape = (image_width,image_height,1)\n",
    "        inputs =  keras.Input(shape=input_shape, name=\"xs\")\n",
    "        labels =  keras.layers.Input(name=\"ys\", shape=(None,))\n",
    "\n",
    "        conv2d_1 = Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",padding=\"same\",name=\"Conv1\",)(inputs)\n",
    "        batch_1 = BatchNormalization()(conv2d_1)\n",
    "        relu_1 = keras.layers.Activation('relu')(batch_1)\n",
    "        pool_1 = MaxPooling2D((2, 2), name=\"pool1\")(relu_1)\n",
    "    \n",
    "        conv2d_2 =  Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\", name=\"Conv2\",)(pool_1)\n",
    "        batch_2 = BatchNormalization()(conv2d_2)\n",
    "        relu_2 = keras.layers.Activation('relu')(batch_2)\n",
    "        pool_2 = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(relu_2)\n",
    "    \n",
    "        new_shape = ((image_width // 4), (image_height // 4) * 64)\n",
    "        reshape = Reshape(target_shape=new_shape, name=\"reshape\")(pool_2)\n",
    "        dense =  Dense(64, activation=\"relu\", name=\"dense1\")(reshape)\n",
    "        dropout =  Dropout(0.2)(dense)\n",
    "        \n",
    "        blstm_1 =  keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True, dropout=0.25))(dropout)\n",
    "        blstm_2 =  keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True, dropout=0.25))(blstm_1)\n",
    "        blstm_3 =  keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True, dropout=0.25))(blstm_2)\n",
    "        \n",
    "        dense_2 =  Dense(len(char_to_num.get_vocabulary()) + 2, name=\"dense2\")(blstm_3)\n",
    "        y_pred = Activation('softmax', name='softmax')(dense_2)\n",
    "    \n",
    "        output = CTCLayer(name=\"ctc_loss\")(labels, y_pred)\n",
    "\n",
    "        model = Model(inputs=[inputs, labels], outputs=output)\n",
    "        return model\n",
    "    \n",
    "    def fit(self, train_seq, test_seq, epochs=100, earlystop=10):\n",
    "        \n",
    "        filepath=\"offline_without_children_CNN2_blstm.h5\"\n",
    "        early = tf.keras.callbacks.EarlyStopping(patience=earlystop)\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "        self.history = self.model.fit(\n",
    "            train_seq,\n",
    "            validation_data=test_seq,\n",
    "            shuffle=True,\n",
    "            verbose=1,\n",
    "            epochs=epochs,\n",
    "            callbacks=[checkpoint, early]\n",
    "        )\n",
    "        \n",
    "    def get_history(self):\n",
    "        return self.history\n",
    "    \n",
    "    def compile(self):\n",
    "        optimizer = Adam()\n",
    "        self.model.compile(optimizer=optimizer)\n",
    "        \n",
    "    def save_weights(self, file_name=None):\n",
    "        self.model.save_weights(file_name)\n",
    "\n",
    "    def load_weights(self, file_name=None):\n",
    "        self.model.load_weights(file_name)\n",
    "        self.compile()\n",
    "        \n",
    "    def predict(self,eval_data):\n",
    "        pred = self.model.predict(eval_data)\n",
    "        return pred\n",
    "    \n",
    "    def get_model_summary(self):\n",
    "        return self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " xs (InputLayer)                [(None, 128, 32, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 128, 32, 32)  320         ['xs[0][0]']                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 32, 32)  128        ['Conv1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 128, 32, 32)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 64, 16, 32)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " Conv2 (Conv2D)                 (None, 64, 16, 64)   18496       ['pool1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 16, 64)  256         ['Conv2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 64, 16, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)           (None, 32, 8, 64)    0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 32, 512)      0           ['pool2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 32, 64)       32832       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32, 64)       0           ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 32, 256)     197632      ['dropout_1[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, 32, 128)     164352      ['bidirectional_3[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_5 (Bidirectional  (None, 32, 128)     98816       ['bidirectional_4[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 32, 81)       10449       ['bidirectional_5[0][0]']        \n",
      "                                                                                                  \n",
      " ys (InputLayer)                [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 32, 81)       0           ['dense2[0][0]']                 \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)            (None, 32, 81)       0           ['ys[0][0]',                     \n",
      "                                                                  'softmax[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 523,281\n",
      "Trainable params: 523,089\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "offline_model = Offline_Model(preload=False)\n",
    "offline_model.get_model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 13.7723\n",
      "Epoch 1: val_loss improved from inf to 10.34103, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 318s 227ms/step - loss: 13.7723 - val_loss: 10.3410\n",
      "Epoch 2/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 10.6333\n",
      "Epoch 2: val_loss improved from 10.34103 to 8.05530, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 338s 249ms/step - loss: 10.6333 - val_loss: 8.0553\n",
      "Epoch 3/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 8.7513\n",
      "Epoch 3: val_loss improved from 8.05530 to 6.36568, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 331s 244ms/step - loss: 8.7513 - val_loss: 6.3657\n",
      "Epoch 4/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 6.8919\n",
      "Epoch 4: val_loss improved from 6.36568 to 4.89658, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 335s 247ms/step - loss: 6.8919 - val_loss: 4.8966\n",
      "Epoch 5/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 5.4042\n",
      "Epoch 5: val_loss improved from 4.89658 to 3.87021, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 336s 248ms/step - loss: 5.4042 - val_loss: 3.8702\n",
      "Epoch 6/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 4.5879\n",
      "Epoch 6: val_loss improved from 3.87021 to 3.40487, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 340s 250ms/step - loss: 4.5879 - val_loss: 3.4049\n",
      "Epoch 7/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 4.0725\n",
      "Epoch 7: val_loss improved from 3.40487 to 3.06186, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 336s 248ms/step - loss: 4.0725 - val_loss: 3.0619\n",
      "Epoch 8/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 3.7075\n",
      "Epoch 8: val_loss improved from 3.06186 to 2.89447, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 398s 293ms/step - loss: 3.7075 - val_loss: 2.8945\n",
      "Epoch 9/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 3.4480\n",
      "Epoch 9: val_loss improved from 2.89447 to 2.74341, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 450s 331ms/step - loss: 3.4480 - val_loss: 2.7434\n",
      "Epoch 10/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 3.2330\n",
      "Epoch 10: val_loss improved from 2.74341 to 2.54710, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 472s 348ms/step - loss: 3.2330 - val_loss: 2.5471\n",
      "Epoch 11/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 3.0597\n",
      "Epoch 11: val_loss improved from 2.54710 to 2.46951, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 489s 361ms/step - loss: 3.0597 - val_loss: 2.4695\n",
      "Epoch 12/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 2.9288\n",
      "Epoch 12: val_loss did not improve from 2.46951\n",
      "1357/1357 [==============================] - 501s 369ms/step - loss: 2.9288 - val_loss: 2.5346\n",
      "Epoch 13/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 2.7816\n",
      "Epoch 13: val_loss did not improve from 2.46951\n",
      "1357/1357 [==============================] - 472s 347ms/step - loss: 2.7816 - val_loss: 2.4887\n",
      "Epoch 14/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 2.6699\n",
      "Epoch 14: val_loss improved from 2.46951 to 2.43562, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 467s 344ms/step - loss: 2.6699 - val_loss: 2.4356\n",
      "Epoch 15/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 2.5788\n",
      "Epoch 15: val_loss improved from 2.43562 to 2.16275, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 478s 352ms/step - loss: 2.5788 - val_loss: 2.1627\n",
      "Epoch 16/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 2.4994\n",
      "Epoch 16: val_loss improved from 2.16275 to 2.10550, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 473s 348ms/step - loss: 2.4994 - val_loss: 2.1055\n",
      "Epoch 17/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 2.4221\n",
      "Epoch 17: val_loss improved from 2.10550 to 2.10092, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 480s 354ms/step - loss: 2.4221 - val_loss: 2.1009\n",
      "Epoch 18/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 2.3444\n",
      "Epoch 18: val_loss improved from 2.10092 to 2.10048, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 458s 337ms/step - loss: 2.3444 - val_loss: 2.1005\n",
      "Epoch 19/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 2.2805\n",
      "Epoch 19: val_loss did not improve from 2.10048\n",
      "1357/1357 [==============================] - 460s 339ms/step - loss: 2.2805 - val_loss: 2.1067\n",
      "Epoch 20/50\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 2.2244\n",
      "Epoch 20: val_loss improved from 2.10048 to 1.92173, saving model to offline_without_children_CNN2_blstm.h5\n",
      "1357/1357 [==============================] - 484s 356ms/step - loss: 2.2244 - val_loss: 1.9217\n",
      "Epoch 21/50\n",
      " 713/1357 [==============>...............] - ETA: 3:44 - loss: 2.3457"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-bdfcd30b64f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moffline_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-207136f0b0e3>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_seq, test_seq, epochs, earlystop)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         self.history = self.model.fit(\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0mtrain_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = offline_model.fit(train_tf, validation_tf, epochs=50,earlystop=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_model.save_weights('offline_without_children_CNN2_batch64_blstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred=None, top_n=1):\n",
    "    pred = pred\n",
    "    top_n = top_n\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "   # Use greedy search. For complex tasks, you can use beam search.\n",
    "   \n",
    "    if(top_n>1):\n",
    "        results_beam = []\n",
    "        for i in range(top_n):\n",
    "            results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=False,beam_width=25,top_paths=5)[0][i][\n",
    "                :, :max_len\n",
    "            ]\n",
    "  \n",
    "            output_text = []\n",
    "            for res in results:\n",
    "                res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "                res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "                output_text.append(res)\n",
    "            results_beam.append(output_text)\n",
    "        return results_beam\n",
    "    \n",
    "    elif(top_n==1):\n",
    "        results_beam = keras.backend.ctc_decode(pred, input_length=input_len, greedy=False,beam_width=25,top_paths=1)[0][0][\n",
    "              :, :max_len]\n",
    "\n",
    "        output_beam = []\n",
    "        for res in results_beam:\n",
    "            res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "            res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "            output_beam.append(res)\n",
    "            \n",
    "        results_greedy = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
    "              :, :max_len]\n",
    "   \n",
    "        output_greedy = []\n",
    "        for res in results_greedy:\n",
    "            res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "            res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "            output_greedy.append(res)\n",
    "            \n",
    "        return output_beam, output_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sounded'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = offline_model.predict(test_tf)\n",
    "beam = preds[0]\n",
    "beam = np.reshape(beam,(1,beam.shape[0],beam.shape[1]))\n",
    "beam_pred = decode_batch_predictions(pred=beam,top_n=5)\n",
    "beam_pred[:3][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_beam, pred_greedy = decode_batch_predictions(preds, top_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaro Winkler Offline Model Beam Search CER: 12.78\n",
      "Jaro Winkler Offline Model Beam Search WER: 40.75\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein  as lv\n",
    "total_jaro = 0\n",
    "for i in range(len(pred_beam)):\n",
    "    total_jaro+=lv.jaro(pred_beam[i], test_labels[i])\n",
    "    \n",
    "cer = (1-total_jaro/len(pred_beam))*100\n",
    "print('Jaro Winkler Offline Model Beam Search CER:', round(cer,2))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pred_beam)):\n",
    "    if(pred_beam[i]==test_labels[i]):\n",
    "        count +=1\n",
    "        \n",
    "wer = (1-count/len(test_labels))*100\n",
    "print('Jaro Winkler Offline Model Beam Search WER:', round(wer,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaro Winkler Offline Model Greedy Search CER: 12.5\n",
      "Jaro Winkler Offline Model Greedy Search WER: 38.22\n"
     ]
    }
   ],
   "source": [
    "total_jaro = 0\n",
    "for i in range(len(pred_greedy)):\n",
    "    total_jaro+=lv.jaro(pred_greedy[i], test_labels[i])\n",
    "    \n",
    "cer = (1-total_jaro/len(pred_greedy))*100\n",
    "print('Jaro Winkler Offline Model Greedy Search CER:', round(cer,2))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pred_greedy)):\n",
    "    if(pred_greedy[i]==test_labels[i]):\n",
    "        count +=1\n",
    "        \n",
    "wer = (1-count/len(test_labels))*100\n",
    "print('Jaro Winkler Offline Model Greedy Search WER:', round(wer,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
